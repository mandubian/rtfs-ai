# Plan: RTFS Tooling & LLM Training Dataset Generation

This document outlines the steps to build RTFS parsing/validation tools and use them to generate a synthetic dataset for fine-tuning an LLM to understand and generate RTFS code.

## Steps

1.  **Implement the RTFS Parser:**
    *   **Implementation Language:** Decide primary location (e.g., `acl_compiler` in Rust, or potentially `rtfs_clojure`). Rust is preferred for performance and alignment with `acl_compiler`.
    *   **Input:** RTFS specifications (`specs/syntax_spec.md`, `specs/grammar_spec.md`).
    *   **Process:** Define parsing rules (e.g., using `nom` or `pest` in Rust).
    *   **Output:** An Abstract Syntax Tree (AST) representing the RTFS code structure.

2.  **Implement the RTFS Validator:**
    *   **Input:** Parser-generated AST.
    *   **Process:**
        *   Build upon the AST.
        *   Implement checks for semantic rules derived from `specs/core_concepts.md`, `specs/type_system.md`, `specs/security_model.md`, etc.
        *   Include checks for:
            *   Type consistency (if implementing static analysis).
            *   Contract validation (input/output schemas, capability structure).
            *   Valid tool names (potentially against a predefined registry or standard library spec).
            *   Correct usage of core forms (`let`, `match`, `with-resource`, etc.).
    *   **Output:** Validation status (success or list of errors).

3.  **Develop a Synthetic Data Generator:**
    *   **Strategy:** Choose generation methods. Good starting points:
        *   Template-based generation using `specs/examples.md`.
        *   Grammar-based generation using `specs/grammar_spec.md`.
        *   LLM bootstrapping (generate candidates with a general LLM prompted with specs, then validate).
        *   Mutation of known valid examples.
    *   **Goal:** Generate diverse RTFS samples covering various features (control flow, error handling, resource management, contracts, modules, different data types).
    *   **Output:** Candidate RTFS code snippets (as strings or ASTs).

4.  **Generation & Validation Loop:**
    *   **Process:**
        1.  Run the synthetic data generator to produce a candidate sample.
        2.  Feed the candidate sample into the RTFS parser.
        3.  If parsing succeeds, feed the resulting AST into the RTFS validator.
        4.  If validation succeeds, store the valid RTFS sample.
        5.  Repeat.
    *   **Output:** A collection of validated RTFS code samples.

5.  **Dataset Assembly:**
    *   **Input:** Collection of validated RTFS samples.
    *   **Process:**
        *   Format the samples for LLM fine-tuning. A common format is pairs of:
            *   A natural language description of the task's intent or purpose. (This might need to be generated alongside the RTFS code in Step 3, or potentially generated by another LLM pass based on the validated RTFS code).
            *   The corresponding valid RTFS code.
        *   Ensure variety and balance in the dataset.
    *   **Output:** Formatted fine-tuning dataset (e.g., JSONL file).

6.  **LLM Fine-tuning:**
    *   **Input:** Assembled dataset.
    *   **Process:** Use the dataset to fine-tune a suitable base Large Language Model (e.g., using standard fine-tuning platforms or libraries).
    *   **Goal:** Specialize the LLM to understand RTFS syntax, semantics, and common patterns, enabling it to generate correct RTFS code from natural language intents.
    *   **Output:** A fine-tuned LLM specialized for RTFS generation.
